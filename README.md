# llm-evaluation 
레포트 작성할때 정리한 데이터 및 평가 데이터


### HellaSwag 영문 한글 결과
```
| ChatGPT4 | ChatGPT3,5 | Gemma-7b-it | Mixtral-8x7B-Instruct-v0.1 | openchat-3.5-0106 | Nous-Hermes-2-Mixtral-8x7B-DPO | Solar-Mini |
| 9/10 | 8/10 | 5/10 | 6/10 | 8/10 | 8/10 | 7/10 |  - 영문
| 9(10)/10 | 6/10 | 3/10 | 6/10 | 2/10 | 3/10 | 7(8)/10 | - 한글
| 한글답변 | 멀티턴 이해 불가 | 영어로답변 | 한글답변 | 한글답변 |
```

### 리서치
## 평가 데이터셋

한국(ko-llm)에서는 다음의 데이터셋을 사용하여 한국어 LLM 모델의 성능을 평가하고 있습니다.

- Ko-ARC
- Ko-HellaSwag  
- Ko-MMLU
- Ko-TruthfulQA
- Ko-CommonGen V2

## 평가 도구

모델 평가를 쉽게 할 수 있도록 도와주는 툴로는 다음과 같은 것들이 있습니다.

- lm-evaluation-harness (한국어 평가 지원)
- ko-lm-evaluation-harness

이들 툴을 사용하면 간단한 명령어로 모델들을 평가할 수 있습니다.

## VRAM 요구사항

모델의 파라메터 수에 따른 VRAM 요구사항은 다음과 같습니다.

| 파라메터 수 | FP16 | INT8 (양자화) | INT4 (양자화) |
|-------------|------|----------------|----------------|
| 7B          | 14GB | 7GB            | 4GB            |
| 13B         | 27GB | 14GB           | 7GB            |
| 33B         | 68GB | 34GB           | 17GB           |
| 65B         | 135GB| 68GB           | 34GB           |

## GPU 가격

2024년 3월 27일 기준으로 A100 (80GB) 그래픽카드 가격은 대략 3천만원 수준입니다. A100 80G 1장으로는 65B개의 파라메터를 가진 INT8 (양자화) 모델까지 추론이 가능합니다.

## 모델 크기와 성능

일반적으로 모델의 크기가 커질수록 성능이 향상되는 경향이 있지만, 더 큰 모델이 항상 더 나은 성능을 보장하지는 않습니다. 고품질 데이터로 파인 튜닝된 작은 모델도 경쟁력 있는 성능을 낼 수 있습니다.

또한, 명시적인 지시(instruction tuning)가 모델의 성능 향상에 중요한 역할을 합니다. 이를 통해 모델이 특정 태스크의 뉘앙스를 더 잘 이해할 수 있게 됩니다.
